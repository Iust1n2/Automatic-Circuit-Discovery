{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53827ca9",
   "metadata": {},
   "source": [
    "<h1>ACDC Editing Edges Demo</h1>\n",
    "\n",
    "<p>This notebook gives a high-level overview of the main abstractions used in the ACDC codebase.</p>\n",
    "\n",
    "<p>If you are interested in models that are >10x the size of GPT-2 small, this library currently may be too slow and we would recommend you look at the path patching implementations in `TransformerLens` (forthcoming)</p>\n",
    "\n",
    "<h3>Setup</h2>\n",
    "\n",
    "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3a5c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/neelnanda-io/TransformerLens.git\", \n",
    "    )\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git\", # install ACDC\n",
    "    )\n",
    "    ipython.run_line_magic(\"pip\", \"install torchtyping cmapy\")\n",
    "\n",
    "except Exception as e:\n",
    "    IN_COLAB = False\n",
    "    print(\n",
    "        \"Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\"\n",
    "    )\n",
    "\n",
    "    import numpy # crucial to not get cursed error\n",
    "    import plotly\n",
    "\n",
    "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
    "    # disable this option when developing rather than generating notebook outputs\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
    "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18caeada",
   "metadata": {},
   "source": [
    "<h2>Imports etc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4263eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.induction.utils import get_all_induction_things\n",
    "from acdc.acdc_utils import TorchIndex\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415dc51",
   "metadata": {},
   "source": [
    "<h2>Load in the model and data for the induction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e17e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 40\n",
    "seq_len = 300\n",
    "\n",
    "# load in a tl_model and grab some data\n",
    "all_induction_things = get_all_induction_things(\n",
    "    num_examples=num_examples,\n",
    "    seq_len=seq_len,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "tl_model, toks_int_values, toks_int_values_other, metric, mask_rep = (\n",
    "    all_induction_things.tl_model,\n",
    "    all_induction_things.validation_data,\n",
    "    all_induction_things.validation_patch_data,\n",
    "    all_induction_things.validation_metric,\n",
    "    all_induction_things.validation_mask,\n",
    ")\n",
    "\n",
    "# You should read the get_model function from that file to see what the tl_model is : )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42488dea",
   "metadata": {},
   "source": [
    "<p>Ensure we stay under mem limit on small machines</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2c946",
   "metadata": {},
   "source": [
    "<p>Let's see an example from the dataset.</p>\n",
    "<p> `|` separates tokens </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_NO = 33\n",
    "EXAMPLE_LENGTH = 36\n",
    "\n",
    "print(\n",
    "    \"|\".join(tl_model.to_str_tokens(toks_int_values[EXAMPLE_NO, :EXAMPLE_LENGTH])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd909",
   "metadata": {},
   "source": [
    "<p>This dataset has several examples of induction! F -> #, mon -> ads</p>\n",
    "<p>The `mask_rep` mask is a boolean mask of shape `(num_examples, seq_len)` that indicates where induction is present in the dataset</p>\n",
    "<p> Let's see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e78a30",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "for i in range(EXAMPLE_LENGTH):\n",
    "    if mask_rep[EXAMPLE_NO, i]:\n",
    "        print(f\"At position {i} there is induction\")\n",
    "        print(tl_model.to_str_tokens(toks_int_values[EXAMPLE_NO:EXAMPLE_NO+1, i : i + 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda9629",
   "metadata": {},
   "source": [
    "<p>Let's get the initial loss on the induction examples</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, data, mask):\n",
    "    loss = model(\n",
    "        data,\n",
    "        return_type=\"loss\",\n",
    "        loss_per_token=True,\n",
    "    )\n",
    "    return (loss * mask[:, :-1].int()).sum() / mask[:, :-1].int().sum()\n",
    "\n",
    "\n",
    "print(f\"Loss: {get_loss(tl_model, toks_int_values, mask_rep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ea125",
   "metadata": {},
   "source": [
    "<p>We will now wrap ACDC things inside an `experiment`for further experiments</p>\n",
    "<p>For more advanced usage of the `TLACDCExperiment` object (the main object in this codebase), see the README for links to the `main.py` and its demos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0cff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = TLACDCExperiment(\n",
    "    model=tl_model,\n",
    "    threshold=0.0,\n",
    "    ds=toks_int_values,\n",
    "    ref_ds=None,  # This argument is the corrupted dataset from the ACDC paper. We're going to do zero ablation here so we omit this\n",
    "    metric=metric,\n",
    "    zero_ablation=True,\n",
    "    hook_verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9135b3",
   "metadata": {},
   "source": [
    "\n",
    "<p>Usually, the `TLACDCExperiment` efficiently add hooks to the model in order to do ACDC runs fast.</p>\n",
    "<p>For this tutorial, we'll add <b>ALL</b> the hooks so you can edit connections in the model as easily as possible.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.model.reset_hooks()\n",
    "experiment.setup_model_hooks(\n",
    "    add_sender_hooks=True,\n",
    "    add_receiver_hooks=True,\n",
    "    doing_acdc_runs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c819aa7",
   "metadata": {},
   "source": [
    "Let's take a look at the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ba8ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "for edge_indices, edge in experiment.corr.all_edges().items():\n",
    "    # here's what's inside the edge\n",
    "    receiver_name, receiver_index, sender_name, sender_index = edge_indices\n",
    "\n",
    "    # for now, all edges should be present\n",
    "    assert edge.present, edge_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71930e4d",
   "metadata": {},
   "source": [
    "<p>Let's make a function that's able to turn off all the connections from the nodes to the output, except the induction head (1.5 and 1.6)</p>\n",
    "<p>(we'll later turn ON all connections EXCEPT the induction heads)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa096f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_direct_output_connections(exp, invert=False):\n",
    "    residual_stream_end_name = \"blocks.1.hook_resid_post\"\n",
    "    residual_stream_end_index = TorchIndex([None])\n",
    "    induction_heads = [\n",
    "        (\"blocks.1.attn.hook_result\", TorchIndex([None, None, 5])),\n",
    "        (\"blocks.1.attn.hook_result\", TorchIndex([None, None, 6])),\n",
    "    ]\n",
    "\n",
    "    inputs_to_residual_stream_end = exp.corr.edges[residual_stream_end_name][\n",
    "        residual_stream_end_index\n",
    "    ]\n",
    "    for sender_name in inputs_to_residual_stream_end:\n",
    "        for sender_index in inputs_to_residual_stream_end[sender_name]:\n",
    "            edge = inputs_to_residual_stream_end[sender_name][sender_index]\n",
    "            is_induction_head = (sender_name, sender_index) in induction_heads\n",
    "\n",
    "            if is_induction_head:\n",
    "                edge.present = not invert\n",
    "\n",
    "            else:\n",
    "                edge.present = invert\n",
    "\n",
    "            print(\n",
    "                f\"{'Adding' if (invert == is_induction_head) else 'Removing'} edge from {sender_name} {sender_index} to {residual_stream_end_name} {residual_stream_end_index}\"\n",
    "            )\n",
    "\n",
    "\n",
    "change_direct_output_connections(experiment)\n",
    "print(\n",
    "    \"Loss with only the induction head direct connections:\",\n",
    "    get_loss(experiment.model, toks_int_values, mask_rep).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3012bb",
   "metadata": {},
   "source": [
    "<p>Let's turn ON all the connections EXCEPT the induction heads</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f16d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_direct_output_connections(experiment, invert=True)\n",
    "print(\n",
    "    \"Loss without the induction head direct connections:\",\n",
    "    get_loss(experiment.model, toks_int_values, mask_rep).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b8019",
   "metadata": {},
   "source": [
    "<p>That's much larger!</p>\n",
    "<p>See acdc/main.py for how to run ACDC experiments; try `python acdc/main.py --help` or check the README for the links to this file</p>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
