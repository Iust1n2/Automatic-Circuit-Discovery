{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513b2336",
   "metadata": {},
   "source": [
    "<h1>ACDC Main Demo</h1>\n",
    "\n",
    "<p>This notebook (which doubles as a script) shows several use cases of ACDC</p>\n",
    "\n",
    "<p>The codebase is built on top of https://github.com/neelnanda-io/TransformerLens (source version)</p>\n",
    "\n",
    "<h3>Setup:</h3>\n",
    "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42622c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook. WARNING: you should switch to a High-RAM A100 (you can buy $10 of credits for this). We're working on a low-memory version\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/neelnanda-io/TransformerLens.git\", \n",
    "    )\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git\", # install ACDC\n",
    "    )\n",
    "    ipython.run_line_magic(\"pip\", \"install torchtyping\")\n",
    "    ipython.run_line_magic(\"pip\", \"install cmapy\")\n",
    "    try:\n",
    "        ipython.run_line_magic(\n",
    "            \"pip\",\n",
    "            \"install git+https://github.com/deepmind/tracr.git@e75ecdaec12bf2d831a60e54d4270e8fa31fb537#egg=tracr\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    IN_COLAB = False\n",
    "    print(\n",
    "        \"Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\"\n",
    "    )\n",
    "\n",
    "    import numpy # crucial to not get cursed error\n",
    "    import plotly\n",
    "\n",
    "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
    "    # disable this option when developing rather than generating notebook outputs\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
    "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72c2a1",
   "metadata": {},
   "source": [
    "<h2>Imports etc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import huggingface_hub\n",
    "import graphviz\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from acdc.acdc_graphics import show\n",
    "from transformer_lens.HookedTransformer import (\n",
    "    HookedTransformer,\n",
    ")\n",
    "try:\n",
    "    from acdc.tracr_task.utils import (\n",
    "        get_all_tracr_things,\n",
    "        get_tracr_model_input_and_tl_model,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
    "from acdc.docstring.utils import get_all_docstring_things\n",
    "from acdc.acdc_utils import (\n",
    "    make_nd_dict,\n",
    "    reset_network,\n",
    "    shuffle_tensor,\n",
    "    cleanup,\n",
    "    ct,\n",
    "    TorchIndex,\n",
    "    Edge,\n",
    "    EdgeType,\n",
    ")  # these introduce several important classes !!!\n",
    "\n",
    "from acdc.TLACDCCorrespondence import TLACDCCorrespondence\n",
    "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "\n",
    "from acdc.acdc_utils import (\n",
    "    kl_divergence,\n",
    ")\n",
    "from acdc.ioi.utils import (\n",
    "    get_all_ioi_things,\n",
    "    get_gpt2_small,\n",
    ")\n",
    "from acdc.induction.utils import (\n",
    "    get_all_induction_things,\n",
    "    get_validation_data,\n",
    "    get_good_induction_candidates,\n",
    "    get_mask_repeat_candidates,\n",
    ")\n",
    "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
    "from acdc.acdc_graphics import (\n",
    "    build_colorscheme,\n",
    "    show,\n",
    ")\n",
    "import argparse\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e5f24",
   "metadata": {},
   "source": [
    "<h2>ACDC Experiment Setup</h2>\n",
    "<p>We use a `parser to set all the options for the ACDC experiment.\n",
    "This is still usable in notebooks! We can pass a string to the parser, see below.\n",
    "We'll reproduce </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Used to launch ACDC runs. Only task and threshold are required\")\n",
    "\n",
    "task_choices = ['ioi', 'docstring', 'induction', 'tracr-reverse', 'tracr-proportion', 'greaterthan']\n",
    "parser.add_argument('--task', type=str, required=True, choices=task_choices, help=f'Choose a task from the available options: {task_choices}')\n",
    "parser.add_argument('--threshold', type=float, required=True, help='Value for THRESHOLD')\n",
    "parser.add_argument('--first-cache-cpu', type=bool, required=False, default=True, help='Value for FIRST_CACHE_CPU')\n",
    "parser.add_argument('--second-cache-cpu', type=bool, required=False, default=True, help='Value for SECOND_CACHE_CPU')\n",
    "parser.add_argument('--zero-ablation', action='store_true', help='Use zero ablation')\n",
    "parser.add_argument('--using-wandb', action='store_true', help='Use wandb')\n",
    "parser.add_argument('--wandb-entity-name', type=str, required=False, default=\"remix_school-of-rock\", help='Value for WANDB_ENTITY_NAME')\n",
    "parser.add_argument('--wandb-group-name', type=str, required=False, default=\"default\", help='Value for WANDB_GROUP_NAME')\n",
    "parser.add_argument('--wandb-project-name', type=str, required=False, default=\"acdc\", help='Value for WANDB_PROJECT_NAME')\n",
    "parser.add_argument('--wandb-run-name', type=str, required=False, default=None, help='Value for WANDB_RUN_NAME')\n",
    "parser.add_argument(\"--wandb-dir\", type=str, default=\"/tmp/wandb\")\n",
    "parser.add_argument(\"--wandb-mode\", type=str, default=\"online\")\n",
    "parser.add_argument('--indices-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--names-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--device', type=str, default=\"cuda\")\n",
    "parser.add_argument('--reset-network', type=int, default=0, help=\"Whether to reset the network we're operating on before running interp on it\")\n",
    "parser.add_argument('--metric', type=str, default=\"kl_div\", help=\"Which metric to use for the experiment\")\n",
    "parser.add_argument('--torch-num-threads', type=int, default=0, help=\"How many threads to use for torch (0=all)\")\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument(\"--max-num-epochs\",type=int, default=100_000)\n",
    "parser.add_argument('--single-step', action='store_true', help='Use single step, mostly for testing')\n",
    "\n",
    "if ipython is not None:\n",
    "    # we are in a notebook\n",
    "    # you can put the command you would like to run as the ... in r\"\"\"...\"\"\"\n",
    "    args = parser.parse_args( # TODO add back zero ablation\n",
    "        [line.strip() for line in r\"\"\"--task=induction\\\n",
    "--zero-ablation\\\n",
    "--threshold=0.5623\\\n",
    "--indices-mode=reverse\\\n",
    "--first-cache-cpu=False\\\n",
    "--second-cache-cpu=False\\\n",
    "--max-num-epochs=100000\"\"\".split(\"\\\\\\n\")]\n",
    "    )\n",
    "else:\n",
    "    # read from command line\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# process args\n",
    "\n",
    "if args.torch_num_threads > 0:\n",
    "    torch.set_num_threads(args.torch_num_threads)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "TASK = args.task\n",
    "FIRST_CACHE_CPU = args.first_cache_cpu\n",
    "SECOND_CACHE_CPU = args.second_cache_cpu\n",
    "THRESHOLD = args.threshold  # only used if >= 0.0\n",
    "ZERO_ABLATION = True if args.zero_ablation else False\n",
    "USING_WANDB = True if args.using_wandb else False\n",
    "WANDB_ENTITY_NAME = args.wandb_entity_name\n",
    "WANDB_PROJECT_NAME = args.wandb_project_name\n",
    "WANDB_RUN_NAME = args.wandb_run_name\n",
    "WANDB_GROUP_NAME = args.wandb_group_name\n",
    "INDICES_MODE = args.indices_mode\n",
    "NAMES_MODE = args.names_mode\n",
    "DEVICE = args.device\n",
    "RESET_NETWORK = args.reset_network\n",
    "SINGLE_STEP = True if args.single_step else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b432ec0",
   "metadata": {},
   "source": [
    "<h2>Setup Task</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d871082",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_metric = None  # some tasks only have one metric\n",
    "use_pos_embed = TASK.startswith(\"tracr\")\n",
    "\n",
    "if TASK == \"ioi\":\n",
    "    num_examples = 100\n",
    "    things = get_all_ioi_things(\n",
    "        num_examples=num_examples, device=DEVICE, metric_name=args.metric\n",
    "    )\n",
    "elif TASK == \"tracr-reverse\":\n",
    "    num_examples = 6\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"reverse\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"tracr-proportion\":\n",
    "    num_examples = 50\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"proportion\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"induction\":\n",
    "    num_examples = 10 if IN_COLAB else 50\n",
    "    seq_len = 300\n",
    "    # TODO initialize the `tl_model` with the right model\n",
    "    things = get_all_induction_things(\n",
    "        num_examples=num_examples, seq_len=seq_len, device=DEVICE, metric=args.metric\n",
    "    )\n",
    "elif TASK == \"docstring\":\n",
    "    num_examples = 50\n",
    "    seq_len = 41\n",
    "    things = get_all_docstring_things(\n",
    "        num_examples=num_examples,\n",
    "        seq_len=seq_len,\n",
    "        device=DEVICE,\n",
    "        metric_name=args.metric,\n",
    "        correct_incorrect_wandb=True,\n",
    "    )\n",
    "elif TASK == \"greaterthan\":\n",
    "    num_examples = 100\n",
    "    things = get_all_greaterthan_things(\n",
    "        num_examples=num_examples, metric_name=args.metric, device=DEVICE\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task {TASK}\")\n",
    "\n",
    "\n",
    "validation_metric = things.validation_metric\n",
    "\n",
    "toks_int_values = things.validation_data\n",
    "toks_int_values_other = things.validation_patch_data\n",
    "\n",
    "tl_model = things.tl_model\n",
    "\n",
    "if RESET_NETWORK:\n",
    "    reset_network(TASK, DEVICE, tl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7d5767",
   "metadata": {},
   "source": [
    "<h2>Setup ACDC Experiment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make notes for potential wandb run\n",
    "try:\n",
    "    with open(__file__, \"r\") as f:\n",
    "        notes = f.read()\n",
    "except:\n",
    "    notes = \"No notes generated, expected when running in an .ipynb file\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "\n",
    "# Save some mem\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Setup wandb if needed\n",
    "if WANDB_RUN_NAME is None or IPython.get_ipython() is not None:\n",
    "    WANDB_RUN_NAME = f\"{ct()}{'_randomindices' if INDICES_MODE=='random' else ''}_{THRESHOLD}{'_zero' if ZERO_ABLATION else ''}\"\n",
    "else:\n",
    "    assert WANDB_RUN_NAME is not None, \"I want named runs, always\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "exp = TLACDCExperiment(\n",
    "    model=tl_model,\n",
    "    threshold=THRESHOLD,\n",
    "    using_wandb=USING_WANDB,\n",
    "    wandb_entity_name=WANDB_ENTITY_NAME,\n",
    "    wandb_project_name=WANDB_PROJECT_NAME,\n",
    "    wandb_run_name=WANDB_RUN_NAME,\n",
    "    wandb_group_name=WANDB_GROUP_NAME,\n",
    "    wandb_notes=notes,\n",
    "    wandb_dir=args.wandb_dir,\n",
    "    wandb_mode=args.wandb_mode,\n",
    "    wandb_config=args,\n",
    "    zero_ablation=ZERO_ABLATION,\n",
    "    ds=toks_int_values,\n",
    "    ref_ds=toks_int_values_other,\n",
    "    metric=validation_metric,\n",
    "    second_metric=second_metric,\n",
    "    verbose=True,\n",
    "    indices_mode=INDICES_MODE,\n",
    "    names_mode=NAMES_MODE,\n",
    "    second_cache_cpu=SECOND_CACHE_CPU,\n",
    "    hook_verbose=False,\n",
    "    first_cache_cpu=FIRST_CACHE_CPU,\n",
    "    add_sender_hooks=True,\n",
    "    use_pos_embed=use_pos_embed,\n",
    "    add_receiver_hooks=False,\n",
    "    remove_redundant=False,\n",
    "    show_full_index=use_pos_embed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90e321",
   "metadata": {},
   "source": [
    "<h2>Run steps of ACDC: iterate over a NODE in the model's computational graph</h2>\n",
    "<p>WARNING! This will take a few minutes to run, but there should be rolling nice pictures too : )</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3222799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.max_num_epochs):\n",
    "    exp.step(testing=False)\n",
    "\n",
    "    show(\n",
    "        exp.corr,\n",
    "        f\"ims/img_new_{i+1}.png\",\n",
    "        show_full_index=use_pos_embed,\n",
    "    )\n",
    "\n",
    "    if IN_COLAB or ipython is not None:\n",
    "        # so long as we're not running this as a script, show the image!\n",
    "        display(Image(f\"ims/img_new_{i+1}.png\"))\n",
    "\n",
    "    print(i, \"-\" * 50)\n",
    "    print(exp.count_no_edges())\n",
    "\n",
    "    if i == 0:\n",
    "        exp.save_edges(\"edges.pkl\")\n",
    "\n",
    "    if exp.current_node is None or SINGLE_STEP:\n",
    "        break\n",
    "\n",
    "exp.save_edges(\"another_final_edges.pkl\")\n",
    "\n",
    "if USING_WANDB:\n",
    "    edges_fname = f\"edges.pth\"\n",
    "    exp.save_edges(edges_fname)\n",
    "    artifact = wandb.Artifact(edges_fname, type=\"dataset\")\n",
    "    artifact.add_file(edges_fname)\n",
    "    wandb.log_artifact(artifact)\n",
    "    os.remove(edges_fname)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dadf7",
   "metadata": {},
   "source": [
    "<h2>Save the final subgraph of the model</h2>\n",
    "<p>There are more than `exp.count_no_edges()` here because we include some \"placeholder\" edges needed to make ACDC work that don't actually matter</p>\n",
    "<p>Also note that the final image has more than 12 edges, because the edges from a0.0_q and a0.0_k are not connected to the input</p>\n",
    "<p>We recover minimal induction machinery! `embed -> a0.0_v -> a1.6k`</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_subgraph(\n",
    "    return_it=True,\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
