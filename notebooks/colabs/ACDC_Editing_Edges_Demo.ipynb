{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d341c26a",
   "metadata": {
    "papermill": {
     "duration": 0.009145,
     "end_time": "2023-06-06T20:11:33.023778",
     "exception": false,
     "start_time": "2023-06-06T20:11:33.014633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>ACDC Editing Edges Demo</h1>\n",
    "\n",
    "<p>This notebook gives a high-level overview of the main abstractions used in the ACDC codebase.</p>\n",
    "\n",
    "<p>If you are interested in models that are >10x the size of GPT-2 small, this library currently may be too slow and we would recommend you look at the path patching implementations in `TransformerLens` (forthcoming)</p>\n",
    "\n",
    "<h3>Setup</h2>\n",
    "\n",
    "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e49633a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:33.039813Z",
     "iopub.status.busy": "2023-06-06T20:11:33.039407Z",
     "iopub.status.idle": "2023-06-06T20:11:33.244955Z",
     "shell.execute_reply": "2023-06-06T20:11:33.244000Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.217851,
     "end_time": "2023-06-06T20:11:33.247373",
     "exception": false,
     "start_time": "2023-06-06T20:11:33.029522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git@arthur-patch-resid-mid\", # install a patched TL\n",
    "    )\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git\", # install ACDC\n",
    "    )\n",
    "    ipython.run_line_magic(\"pip\", \"install torchtyping cmapy\")\n",
    "\n",
    "except Exception as e:\n",
    "    IN_COLAB = False\n",
    "    print(\n",
    "        \"Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\"\n",
    "    )\n",
    "\n",
    "    import numpy # crucial to not get cursed error\n",
    "    import plotly\n",
    "\n",
    "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
    "    # disable this option when developing rather than generating notebook outputs\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
    "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dd504",
   "metadata": {
    "papermill": {
     "duration": 0.003376,
     "end_time": "2023-06-06T20:11:33.257994",
     "exception": false,
     "start_time": "2023-06-06T20:11:33.254618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Imports etc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f089ef4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:33.266529Z",
     "iopub.status.busy": "2023-06-06T20:11:33.265466Z",
     "iopub.status.idle": "2023-06-06T20:11:35.835899Z",
     "shell.execute_reply": "2023-06-06T20:11:35.834862Z"
    },
    "papermill": {
     "duration": 2.577435,
     "end_time": "2023-06-06T20:11:35.838559",
     "exception": false,
     "start_time": "2023-06-06T20:11:33.261124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Are you sure you have an up-to-date TransformerLens installed? As of 6th June 2023, `select_compatible_kwargs` should be importable (this was added at the same time as the functionality needed for ACDC) but there is an error e=ImportError(\"cannot import name 'select_compatible_kwargs' from 'transformer_lens.utils' (/opt/conda/lib/python3.10/site-packages/transformer_lens/utils.py)\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.induction.utils import get_all_induction_things\n",
    "from acdc.acdc_utils import TorchIndex\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9609d",
   "metadata": {
    "papermill": {
     "duration": 0.00549,
     "end_time": "2023-06-06T20:11:35.851763",
     "exception": false,
     "start_time": "2023-06-06T20:11:35.846273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Load in the model and data for the induction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9f75a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:35.865860Z",
     "iopub.status.busy": "2023-06-06T20:11:35.865457Z",
     "iopub.status.idle": "2023-06-06T20:11:39.552962Z",
     "shell.execute_reply": "2023-06-06T20:11:39.552049Z"
    },
    "papermill": {
     "duration": 3.695478,
     "end_time": "2023-06-06T20:11:39.554801",
     "exception": false,
     "start_time": "2023-06-06T20:11:35.859323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model redwood_attn_2l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "num_examples = 40\n",
    "seq_len = 300\n",
    "\n",
    "# load in a tl_model and grab some data\n",
    "all_induction_things = get_all_induction_things(\n",
    "    num_examples=num_examples,\n",
    "    seq_len=seq_len,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "tl_model, toks_int_values, toks_int_values_other, metric, mask_rep = (\n",
    "    all_induction_things.tl_model,\n",
    "    all_induction_things.validation_data,\n",
    "    all_induction_things.validation_patch_data,\n",
    "    all_induction_things.validation_metric,\n",
    "    all_induction_things.validation_mask,\n",
    ")\n",
    "\n",
    "# You should read the get_model function from that file to see what the tl_model is : )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6aa04",
   "metadata": {
    "papermill": {
     "duration": 0.005543,
     "end_time": "2023-06-06T20:11:39.564683",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.559140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>Ensure we stay under mem limit on small machines</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141a9a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:39.578602Z",
     "iopub.status.busy": "2023-06-06T20:11:39.578244Z",
     "iopub.status.idle": "2023-06-06T20:11:39.832127Z",
     "shell.execute_reply": "2023-06-06T20:11:39.831033Z"
    },
    "papermill": {
     "duration": 0.262652,
     "end_time": "2023-06-06T20:11:39.834653",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.572001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eabee2",
   "metadata": {
    "papermill": {
     "duration": 0.003837,
     "end_time": "2023-06-06T20:11:39.846289",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.842452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>Let's see an example from the dataset.</p>\n",
    "<p> `|` separates tokens </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ed667c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:39.854026Z",
     "iopub.status.busy": "2023-06-06T20:11:39.853789Z",
     "iopub.status.idle": "2023-06-06T20:11:39.892969Z",
     "shell.execute_reply": "2023-06-06T20:11:39.891996Z"
    },
    "papermill": {
     "duration": 0.04552,
     "end_time": "2023-06-06T20:11:39.895075",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.849555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[END]| State|ful| comput|ations| in| F|#| with| update| mon|ads|\n",
      "|\n",
      "|Most| discussions| about| mon|ads|,| even| in| F|#|,| start| by| looking| at| the| well|-|known| standard| mon|ads\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_NO = 33\n",
    "EXAMPLE_LENGTH = 36\n",
    "\n",
    "print(\n",
    "    \"|\".join(tl_model.to_str_tokens(toks_int_values[EXAMPLE_NO, :EXAMPLE_LENGTH])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e584e",
   "metadata": {
    "papermill": {
     "duration": 0.004047,
     "end_time": "2023-06-06T20:11:39.906685",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.902638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>This dataset has several examples of induction! F -> #, mon -> ads</p>\n",
    "<p>The `mask_rep` mask is a boolean mask of shape `(num_examples, seq_len)` that indicates where induction is present in the dataset</p>\n",
    "<p> Let's see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd866df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:39.914856Z",
     "iopub.status.busy": "2023-06-06T20:11:39.914504Z",
     "iopub.status.idle": "2023-06-06T20:11:39.949721Z",
     "shell.execute_reply": "2023-06-06T20:11:39.948787Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.042002,
     "end_time": "2023-06-06T20:11:39.952022",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.910020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At position 17 there is induction\n",
      "[' mon']\n",
      "At position 22 there is induction\n",
      "[' F']\n",
      "At position 34 there is induction\n",
      "[' mon']\n"
     ]
    }
   ],
   "source": [
    "for i in range(EXAMPLE_LENGTH):\n",
    "    if mask_rep[EXAMPLE_NO, i]:\n",
    "        print(f\"At position {i} there is induction\")\n",
    "        print(tl_model.to_str_tokens(toks_int_values[EXAMPLE_NO:EXAMPLE_NO+1, i : i + 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46a563",
   "metadata": {
    "papermill": {
     "duration": 0.003485,
     "end_time": "2023-06-06T20:11:39.963131",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.959646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>Let's get the initial loss on the induction examples</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63a1f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:39.971885Z",
     "iopub.status.busy": "2023-06-06T20:11:39.970974Z",
     "iopub.status.idle": "2023-06-06T20:11:40.042230Z",
     "shell.execute_reply": "2023-06-06T20:11:40.041208Z"
    },
    "papermill": {
     "duration": 0.077931,
     "end_time": "2023-06-06T20:11:40.044443",
     "exception": false,
     "start_time": "2023-06-06T20:11:39.966512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8858892917633057\n"
     ]
    }
   ],
   "source": [
    "def get_loss(model, data, mask):\n",
    "    loss = model(\n",
    "        data,\n",
    "        return_type=\"loss\",\n",
    "        loss_per_token=True,\n",
    "    )\n",
    "    return (loss * mask[:, :-1].int()).sum() / mask[:, :-1].int().sum()\n",
    "\n",
    "\n",
    "print(f\"Loss: {get_loss(tl_model, toks_int_values, mask_rep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9eb291",
   "metadata": {
    "papermill": {
     "duration": 0.003422,
     "end_time": "2023-06-06T20:11:40.055433",
     "exception": false,
     "start_time": "2023-06-06T20:11:40.052011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p>We will now wrap ACDC things inside an `experiment`for further experiments</p>\n",
    "<p>For more advanced usage of the `TLACDCExperiment` object (the main object in this codebase), see the README for links to the `main.py` and its demos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5ebd1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:11:40.063532Z",
     "iopub.status.busy": "2023-06-06T20:11:40.063293Z",
     "iopub.status.idle": "2023-06-06T20:12:19.304940Z",
     "shell.execute_reply": "2023-06-06T20:12:19.303767Z"
    },
    "papermill": {
     "duration": 39.257613,
     "end_time": "2023-06-06T20:12:19.316555",
     "exception": true,
     "start_time": "2023-06-06T20:11:40.058942",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_final.hook_normalized\n",
      "ln_final.hook_scale\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_pos_embed\n",
      "hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.1.hook_resid_post, [:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_61980/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3900284895.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_61980/3900284895.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">157</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: metric(x).item()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric = second_metric                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>157 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_cur_metric()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.threshold = threshold                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ref_ds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.zero_ablation, <span style=\"color: #808000; text-decoration-color: #808000\">\"If you're doing random ab</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">188</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_cur_metric</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">185 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_cur_metric</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, recalc_metric=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, recalc_edges=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, initial=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> recalc_metric:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ds)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>188 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cur_metric = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric(logits)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cur_second_metric = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric(logits)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">155</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │   │   │   │   </span>config=wandb_config,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>155 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: metric(x).item()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric = second_metric                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_cur_metric()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">acdc_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">52</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kl_divergence</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 │   │   </span>base_model_logprobs = base_model_logprobs[:, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, :]                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 │   </span>logprobs = F.log_softmax(logits, dim=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 52 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>kl_div = F.kl_div(logprobs, base_model_logprobs, log_target=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, reduction=<span style=\"color: #808000; text-decoration-color: #808000\">\"none\"</span>).   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mask_repeat_candidates <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> kl_div.shape == mask_repeat_candidates.shape, (kl_div.shape, mask_repeat_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2928</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kl_div</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2925 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2926 │   │   │   </span>reduction_enum = _Reduction.get_enum(reduction)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2927 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2928 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>reduced = torch.kl_div(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, reduction_enum, log_target=log_target)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2930 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> reduction == <span style=\"color: #808000; text-decoration-color: #808000\">\"batchmean\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.dim() != <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2931 │   │   </span>reduced = reduced / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size()[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.25</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.65</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.25</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.63</span> GiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.83</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_61980/\u001b[0m\u001b[1;33m3900284895.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_61980/3900284895.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m157\u001b[0m in \u001b[92m__init__\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.metric = \u001b[94mlambda\u001b[0m x: metric(x).item()                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.second_metric = second_metric                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m157 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update_cur_metric()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.threshold = threshold                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.ref_ds \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.zero_ablation, \u001b[33m\"\u001b[0m\u001b[33mIf you\u001b[0m\u001b[33m'\u001b[0m\u001b[33mre doing random ab\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m188\u001b[0m in \u001b[92mupdate_cur_metric\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m185 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mupdate_cur_metric\u001b[0m(\u001b[96mself\u001b[0m, recalc_metric=\u001b[94mTrue\u001b[0m, recalc_edges=\u001b[94mTrue\u001b[0m, initial=\u001b[94mFalse\u001b[0m):     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m recalc_metric:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.model(\u001b[96mself\u001b[0m.ds)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m188 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.cur_metric = \u001b[96mself\u001b[0m.metric(logits)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.second_metric \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.cur_second_metric = \u001b[96mself\u001b[0m.second_metric(logits)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92m<lambda>\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mconfig=wandb_config,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.metric = \u001b[94mlambda\u001b[0m x: metric(x).item()                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.second_metric = second_metric                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update_cur_metric()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33macdc_utils.py\u001b[0m:\u001b[94m52\u001b[0m in \u001b[92mkl_divergence\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   │   \u001b[0mbase_model_logprobs = base_model_logprobs[:, -\u001b[94m1\u001b[0m, :]                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   \u001b[0mlogprobs = F.log_softmax(logits, dim=-\u001b[94m1\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 52 \u001b[2m│   \u001b[0mkl_div = F.kl_div(logprobs, base_model_logprobs, log_target=\u001b[94mTrue\u001b[0m, reduction=\u001b[33m\"\u001b[0m\u001b[33mnone\u001b[0m\u001b[33m\"\u001b[0m).   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m mask_repeat_candidates \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m kl_div.shape == mask_repeat_candidates.shape, (kl_div.shape, mask_repeat_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2928\u001b[0m in \u001b[92mkl_div\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2925 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2926 \u001b[0m\u001b[2m│   │   │   \u001b[0mreduction_enum = _Reduction.get_enum(reduction)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2927 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2928 \u001b[2m│   \u001b[0mreduced = torch.kl_div(\u001b[96minput\u001b[0m, target, reduction_enum, log_target=log_target)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2929 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2930 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m reduction == \u001b[33m\"\u001b[0m\u001b[33mbatchmean\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m \u001b[96minput\u001b[0m.dim() != \u001b[94m0\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2931 \u001b[0m\u001b[2m│   │   \u001b[0mreduced = reduced / \u001b[96minput\u001b[0m.size()[\u001b[94m0\u001b[0m]                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m2.25\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.65\u001b[0m GiB total capacity; \u001b[1;36m18.25\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m1.63\u001b[0m GiB free; \u001b[1;36m18.83\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = TLACDCExperiment(\n",
    "    model=tl_model,\n",
    "    threshold=0.0,\n",
    "    ds=toks_int_values,\n",
    "    ref_ds=None,  # This argument is the corrupted dataset from the ACDC paper. We're going to do zero ablation here so we omit this\n",
    "    metric=metric,\n",
    "    zero_ablation=True,\n",
    "    hook_verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772e724",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<p>Usually, the `TLACDCExperiment` efficiently add hooks to the model in order to do ACDC runs fast.</p>\n",
    "<p>For this tutorial, we'll add <b>ALL</b> the hooks so you can edit connections in the model as easily as possible.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9e387",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment.model.reset_hooks()\n",
    "experiment.setup_model_hooks(\n",
    "    add_sender_hooks=True,\n",
    "    add_receiver_hooks=True,\n",
    "    doing_acdc_runs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1aeb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a084d",
   "metadata": {
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for edge_indices, edge in experiment.corr.all_edges().items():\n",
    "    # here's what's inside the edge\n",
    "    receiver_name, receiver_index, sender_name, sender_index = edge_indices\n",
    "\n",
    "    # for now, all edges should be present\n",
    "    assert edge.present, edge_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e8916",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<p>Let's make a function that's able to turn off all the connections from the nodes to the output, except the induction head (1.5 and 1.6)</p>\n",
    "<p>(we'll later turn ON all connections EXCEPT the induction heads)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b8d30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_direct_output_connections(exp, invert=False):\n",
    "    residual_stream_end_name = \"blocks.1.hook_resid_post\"\n",
    "    residual_stream_end_index = TorchIndex([None])\n",
    "    induction_heads = [\n",
    "        (\"blocks.1.attn.hook_result\", TorchIndex([None, None, 5])),\n",
    "        (\"blocks.1.attn.hook_result\", TorchIndex([None, None, 6])),\n",
    "    ]\n",
    "\n",
    "    inputs_to_residual_stream_end = exp.corr.edges[residual_stream_end_name][\n",
    "        residual_stream_end_index\n",
    "    ]\n",
    "    for sender_name in inputs_to_residual_stream_end:\n",
    "        for sender_index in inputs_to_residual_stream_end[sender_name]:\n",
    "            edge = inputs_to_residual_stream_end[sender_name][sender_index]\n",
    "            is_induction_head = (sender_name, sender_index) in induction_heads\n",
    "\n",
    "            if is_induction_head:\n",
    "                edge.present = not invert\n",
    "\n",
    "            else:\n",
    "                edge.present = invert\n",
    "\n",
    "            print(\n",
    "                f\"{'Adding' if (invert == is_induction_head) else 'Removing'} edge from {sender_name} {sender_index} to {residual_stream_end_name} {residual_stream_end_index}\"\n",
    "            )\n",
    "\n",
    "\n",
    "change_direct_output_connections(experiment)\n",
    "print(\n",
    "    \"Loss with only the induction head direct connections:\",\n",
    "    get_loss(experiment.model, toks_int_values, mask_rep).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ab05a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<p>Let's turn ON all the connections EXCEPT the induction heads</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b4adc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "change_direct_output_connections(experiment, invert=True)\n",
    "print(\n",
    "    \"Loss without the induction head direct connections:\",\n",
    "    get_loss(experiment.model, toks_int_values, mask_rep).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ebf3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<p>That's much larger!</p>\n",
    "<p>See acdc/main.py for how to run ACDC experiments; try `python acdc/main.py --help` or check the README for the links to this file</p>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.429309,
   "end_time": "2023-06-06T20:12:22.118087",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/_converted/editing_edges.ipynb",
   "output_path": "notebooks/colabs/ACDC_Editing_Edges_Demo.ipynb",
   "parameters": {},
   "start_time": "2023-06-06T20:11:31.688778",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}