{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b426b853",
   "metadata": {
    "papermill": {
     "duration": 0.002781,
     "end_time": "2023-06-06T20:00:07.305491",
     "exception": false,
     "start_time": "2023-06-06T20:00:07.302710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>ACDC Main Demo</h1>\n",
    "\n",
    "<p>This notebook (which doubles as a script) shows several use cases of ACDC</p>\n",
    "\n",
    "<p>This codebase is a fork of https://github.com/neelnanda-io/TransformerLens with changes that will hopefully be merged soon</p>\n",
    "\n",
    "<h3>Setup:</h3>\n",
    "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b212e80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:00:07.318127Z",
     "iopub.status.busy": "2023-06-06T20:00:07.317764Z",
     "iopub.status.idle": "2023-06-06T20:00:07.516171Z",
     "shell.execute_reply": "2023-06-06T20:00:07.515236Z"
    },
    "papermill": {
     "duration": 0.207414,
     "end_time": "2023-06-06T20:00:07.518636",
     "exception": false,
     "start_time": "2023-06-06T20:00:07.311222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git@arthur-patch-resid-mid\", # install a patched TL\n",
    "    )\n",
    "    ipython.run_line_magic(\n",
    "        \"pip\",\n",
    "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git\", # install ACDC\n",
    "    )\n",
    "    ipython.run_line_magic(\"pip\", \"install torchtyping\")\n",
    "    ipython.run_line_magic(\"pip\", \"install cmapy\")\n",
    "    try:\n",
    "        ipython.run_line_magic(\n",
    "            \"pip\",\n",
    "            \"install git+https://github.com/deepmind/tracr.git@e75ecdaec12bf2d831a60e54d4270e8fa31fb537#egg=tracr\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    IN_COLAB = False\n",
    "    print(\n",
    "        \"Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\"\n",
    "    )\n",
    "\n",
    "    import numpy # crucial to not get cursed error\n",
    "    import plotly\n",
    "\n",
    "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
    "    # disable this option when developing rather than generating notebook outputs\n",
    "\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
    "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e910ed",
   "metadata": {
    "papermill": {
     "duration": 0.004688,
     "end_time": "2023-06-06T20:00:07.528500",
     "exception": false,
     "start_time": "2023-06-06T20:00:07.523812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Imports etc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde08ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:00:07.535034Z",
     "iopub.status.busy": "2023-06-06T20:00:07.534586Z",
     "iopub.status.idle": "2023-06-06T20:00:10.794191Z",
     "shell.execute_reply": "2023-06-06T20:00:10.793128Z"
    },
    "papermill": {
     "duration": 3.265614,
     "end_time": "2023-06-06T20:00:10.796784",
     "exception": false,
     "start_time": "2023-06-06T20:00:07.531170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Are you sure you have an up-to-date TransformerLens installed? As of 6th June 2023, `select_compatible_kwargs` should be importable (this was added at the same time as the functionality needed for ACDC) but there is an error e=ImportError(\"cannot import name 'select_compatible_kwargs' from 'transformer_lens.utils' (/opt/conda/lib/python3.10/site-packages/transformer_lens/utils.py)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f4ccf68ec80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import huggingface_hub\n",
    "import graphviz\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from acdc.acdc_graphics import show\n",
    "from transformer_lens.HookedTransformer import (\n",
    "    HookedTransformer,\n",
    ")\n",
    "try:\n",
    "    from acdc.tracr_task.utils import (\n",
    "        get_all_tracr_things,\n",
    "        get_tracr_model_input_and_tl_model,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
    "from acdc.docstring.utils import get_all_docstring_things\n",
    "from acdc.acdc_utils import (\n",
    "    make_nd_dict,\n",
    "    reset_network,\n",
    "    shuffle_tensor,\n",
    "    cleanup,\n",
    "    ct,\n",
    "    TorchIndex,\n",
    "    Edge,\n",
    "    EdgeType,\n",
    ")  # these introduce several important classes !!!\n",
    "\n",
    "from acdc.TLACDCCorrespondence import TLACDCCorrespondence\n",
    "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "\n",
    "from acdc.acdc_utils import (\n",
    "    kl_divergence,\n",
    ")\n",
    "from acdc.ioi.utils import (\n",
    "    get_all_ioi_things,\n",
    "    get_gpt2_small,\n",
    ")\n",
    "from acdc.induction.utils import (\n",
    "    get_all_induction_things,\n",
    "    get_validation_data,\n",
    "    get_good_induction_candidates,\n",
    "    get_mask_repeat_candidates,\n",
    ")\n",
    "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
    "from acdc.acdc_graphics import (\n",
    "    build_colorscheme,\n",
    "    show,\n",
    ")\n",
    "import argparse\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8a4af",
   "metadata": {
    "papermill": {
     "duration": 0.005483,
     "end_time": "2023-06-06T20:00:10.808092",
     "exception": false,
     "start_time": "2023-06-06T20:00:10.802609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>ACDC Experiment Setup</h2>\n",
    "<p>We use a `parser to set all the options for the ACDC experiment.\n",
    "This is still usable in notebooks! We can pass a string to the parser, see below.\n",
    "We'll reproduce </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc8d412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:00:10.820803Z",
     "iopub.status.busy": "2023-06-06T20:00:10.820007Z",
     "iopub.status.idle": "2023-06-06T20:00:10.867602Z",
     "shell.execute_reply": "2023-06-06T20:00:10.866680Z"
    },
    "papermill": {
     "duration": 0.056736,
     "end_time": "2023-06-06T20:00:10.870098",
     "exception": false,
     "start_time": "2023-06-06T20:00:10.813362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Used to launch ACDC runs. Only task and threshold are required\")\n",
    "\n",
    "task_choices = ['ioi', 'docstring', 'induction', 'tracr-reverse', 'tracr-proportion', 'greaterthan']\n",
    "parser.add_argument('--task', type=str, required=True, choices=task_choices, help=f'Choose a task from the available options: {task_choices}')\n",
    "parser.add_argument('--threshold', type=float, required=True, help='Value for THRESHOLD')\n",
    "parser.add_argument('--first-cache-cpu', type=bool, required=False, default=True, help='Value for FIRST_CACHE_CPU')\n",
    "parser.add_argument('--second-cache-cpu', type=bool, required=False, default=True, help='Value for SECOND_CACHE_CPU')\n",
    "parser.add_argument('--zero-ablation', action='store_true', help='Use zero ablation')\n",
    "parser.add_argument('--using-wandb', action='store_true', help='Use wandb')\n",
    "parser.add_argument('--wandb-entity-name', type=str, required=False, default=\"remix_school-of-rock\", help='Value for WANDB_ENTITY_NAME')\n",
    "parser.add_argument('--wandb-group-name', type=str, required=False, default=\"default\", help='Value for WANDB_GROUP_NAME')\n",
    "parser.add_argument('--wandb-project-name', type=str, required=False, default=\"acdc\", help='Value for WANDB_PROJECT_NAME')\n",
    "parser.add_argument('--wandb-run-name', type=str, required=False, default=None, help='Value for WANDB_RUN_NAME')\n",
    "parser.add_argument(\"--wandb-dir\", type=str, default=\"/tmp/wandb\")\n",
    "parser.add_argument(\"--wandb-mode\", type=str, default=\"online\")\n",
    "parser.add_argument('--indices-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--names-mode', type=str, default=\"normal\")\n",
    "parser.add_argument('--device', type=str, default=\"cuda\")\n",
    "parser.add_argument('--reset-network', type=int, default=0, help=\"Whether to reset the network we're operating on before running interp on it\")\n",
    "parser.add_argument('--metric', type=str, default=\"kl_div\", help=\"Which metric to use for the experiment\")\n",
    "parser.add_argument('--torch-num-threads', type=int, default=0, help=\"How many threads to use for torch (0=all)\")\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument(\"--max-num-epochs\",type=int, default=100_000)\n",
    "parser.add_argument('--single-step', action='store_true', help='Use single step, mostly for testing')\n",
    "\n",
    "if ipython is not None:\n",
    "    # we are in a notebook\n",
    "    # you can put the command you would like to run as the ... in r\"\"\"...\"\"\"\n",
    "    args = parser.parse_args( # TODO add back zero ablation\n",
    "        [line.strip() for line in r\"\"\"--task=induction\\\n",
    "--zero-ablation\\\n",
    "--threshold=0.5623\\\n",
    "--indices-mode=reverse\\\n",
    "--first-cache-cpu=False\\\n",
    "--second-cache-cpu=False\\\n",
    "--max-num-epochs=100000\"\"\".split(\"\\\\\\n\")]\n",
    "    )\n",
    "else:\n",
    "    # read from command line\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# process args\n",
    "\n",
    "if args.torch_num_threads > 0:\n",
    "    torch.set_num_threads(args.torch_num_threads)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "TASK = args.task\n",
    "FIRST_CACHE_CPU = args.first_cache_cpu\n",
    "SECOND_CACHE_CPU = args.second_cache_cpu\n",
    "THRESHOLD = args.threshold  # only used if >= 0.0\n",
    "ZERO_ABLATION = True if args.zero_ablation else False\n",
    "USING_WANDB = True if args.using_wandb else False\n",
    "WANDB_ENTITY_NAME = args.wandb_entity_name\n",
    "WANDB_PROJECT_NAME = args.wandb_project_name\n",
    "WANDB_RUN_NAME = args.wandb_run_name\n",
    "WANDB_GROUP_NAME = args.wandb_group_name\n",
    "INDICES_MODE = args.indices_mode\n",
    "NAMES_MODE = args.names_mode\n",
    "DEVICE = args.device\n",
    "RESET_NETWORK = args.reset_network\n",
    "SINGLE_STEP = True if args.single_step else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7d9fe",
   "metadata": {
    "papermill": {
     "duration": 0.003265,
     "end_time": "2023-06-06T20:00:10.878475",
     "exception": false,
     "start_time": "2023-06-06T20:00:10.875210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Setup Task</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c381f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:00:10.886766Z",
     "iopub.status.busy": "2023-06-06T20:00:10.886351Z",
     "iopub.status.idle": "2023-06-06T20:00:15.556083Z",
     "shell.execute_reply": "2023-06-06T20:00:15.555172Z"
    },
    "papermill": {
     "duration": 4.676813,
     "end_time": "2023-06-06T20:00:15.558641",
     "exception": false,
     "start_time": "2023-06-06T20:00:10.881828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model redwood_attn_2l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "second_metric = None  # some tasks only have one metric\n",
    "use_pos_embed = TASK.startswith(\"tracr\")\n",
    "\n",
    "if TASK == \"ioi\":\n",
    "    num_examples = 100\n",
    "    things = get_all_ioi_things(\n",
    "        num_examples=num_examples, device=DEVICE, metric_name=args.metric\n",
    "    )\n",
    "elif TASK == \"tracr-reverse\":\n",
    "    num_examples = 6\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"reverse\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"tracr-proportion\":\n",
    "    num_examples = 50\n",
    "    things = get_all_tracr_things(\n",
    "        task=\"proportion\",\n",
    "        metric_name=args.metric,\n",
    "        num_examples=num_examples,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "elif TASK == \"induction\":\n",
    "    num_examples = 50\n",
    "    seq_len = 300\n",
    "    # TODO initialize the `tl_model` with the right model\n",
    "    things = get_all_induction_things(\n",
    "        num_examples=num_examples, seq_len=seq_len, device=DEVICE, metric=args.metric\n",
    "    )\n",
    "elif TASK == \"docstring\":\n",
    "    num_examples = 50\n",
    "    seq_len = 41\n",
    "    things = get_all_docstring_things(\n",
    "        num_examples=num_examples,\n",
    "        seq_len=seq_len,\n",
    "        device=DEVICE,\n",
    "        metric_name=args.metric,\n",
    "        correct_incorrect_wandb=True,\n",
    "    )\n",
    "elif TASK == \"greaterthan\":\n",
    "    num_examples = 100\n",
    "    things = get_all_greaterthan_things(\n",
    "        num_examples=num_examples, metric_name=args.metric, device=DEVICE\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task {TASK}\")\n",
    "\n",
    "\n",
    "validation_metric = things.validation_metric\n",
    "\n",
    "toks_int_values = things.validation_data\n",
    "toks_int_values_other = things.validation_patch_data\n",
    "\n",
    "tl_model = things.tl_model\n",
    "\n",
    "if RESET_NETWORK:\n",
    "    reset_network(TASK, DEVICE, tl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8932787",
   "metadata": {
    "papermill": {
     "duration": 0.005449,
     "end_time": "2023-06-06T20:00:15.570160",
     "exception": false,
     "start_time": "2023-06-06T20:00:15.564711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Setup ACDC Experiment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156b5769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:00:15.581821Z",
     "iopub.status.busy": "2023-06-06T20:00:15.581587Z",
     "iopub.status.idle": "2023-06-06T20:01:05.764392Z",
     "shell.execute_reply": "2023-06-06T20:01:05.763174Z"
    },
    "papermill": {
     "duration": 50.191532,
     "end_time": "2023-06-06T20:01:05.767346",
     "exception": true,
     "start_time": "2023-06-06T20:00:15.575814",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Automatic-Circuit-Discovery/acdc/TLACDCExperiment.py:128: UserWarning:\n",
      "\n",
      "We shall overwrite the ref_ds with zeros.\n",
      "\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.1.hook_resid_post', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_q', 'blocks.1.hook_q_input', 'blocks.1.attn.hook_k', 'blocks.1.hook_k_input', 'blocks.1.attn.hook_v', 'blocks.1.hook_v_input', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_q', 'blocks.0.hook_q_input', 'blocks.0.attn.hook_k', 'blocks.0.hook_k_input', 'blocks.0.attn.hook_v', 'blocks.0.hook_v_input', 'blocks.0.hook_resid_pre'])\n",
      "ln_final.hook_normalized\n",
      "ln_final.hook_scale\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_pos_embed\n",
      "hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.1.hook_resid_post, [:])\n",
      "Adding sender hooks...\n",
      "Now corrupting things..\n",
      "Done corrupting things\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding sender hooks...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_60064/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1222398493.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_60064/1222398493.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">157</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: metric(x).item()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric = second_metric                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>157 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_cur_metric()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.threshold = threshold                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ref_ds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.zero_ablation, <span style=\"color: #808000; text-decoration-color: #808000\">\"If you're doing random ab</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">188</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_cur_metric</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">185 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_cur_metric</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, recalc_metric=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, recalc_edges=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, initial=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> recalc_metric:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ds)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>188 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cur_metric = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric(logits)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cur_second_metric = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric(logits)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TLACDCExperiment.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">155</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │   │   │   │   </span>config=wandb_config,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>155 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.metric = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: metric(x).item()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.second_metric = second_metric                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update_cur_metric()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/Automatic-Circuit-Discovery/acdc/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">acdc_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">52</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kl_divergence</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 │   │   </span>base_model_logprobs = base_model_logprobs[:, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, :]                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 │   </span>logprobs = F.log_softmax(logits, dim=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 52 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>kl_div = F.kl_div(logprobs, base_model_logprobs, log_target=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, reduction=<span style=\"color: #808000; text-decoration-color: #808000\">\"none\"</span>).   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mask_repeat_candidates <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> kl_div.shape == mask_repeat_candidates.shape, (kl_div.shape, mask_repeat_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2928</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kl_div</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2925 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2926 │   │   │   </span>reduction_enum = _Reduction.get_enum(reduction)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2927 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2928 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>reduced = torch.kl_div(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, reduction_enum, log_target=log_target)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2930 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> reduction == <span style=\"color: #808000; text-decoration-color: #808000\">\"batchmean\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.dim() != <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2931 │   │   </span>reduced = reduced / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size()[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.81</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.65</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.90</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.53</span> GiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.93</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_60064/\u001b[0m\u001b[1;33m1222398493.py\u001b[0m:\u001b[94m21\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_60064/1222398493.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m157\u001b[0m in \u001b[92m__init__\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.metric = \u001b[94mlambda\u001b[0m x: metric(x).item()                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.second_metric = second_metric                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m157 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update_cur_metric()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.threshold = threshold                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.ref_ds \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.zero_ablation, \u001b[33m\"\u001b[0m\u001b[33mIf you\u001b[0m\u001b[33m'\u001b[0m\u001b[33mre doing random ab\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m188\u001b[0m in \u001b[92mupdate_cur_metric\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m185 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mupdate_cur_metric\u001b[0m(\u001b[96mself\u001b[0m, recalc_metric=\u001b[94mTrue\u001b[0m, recalc_edges=\u001b[94mTrue\u001b[0m, initial=\u001b[94mFalse\u001b[0m):     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m recalc_metric:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.model(\u001b[96mself\u001b[0m.ds)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m188 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.cur_metric = \u001b[96mself\u001b[0m.metric(logits)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.second_metric \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.cur_second_metric = \u001b[96mself\u001b[0m.second_metric(logits)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33mTLACDCExperiment.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92m<lambda>\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mconfig=wandb_config,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.metric = \u001b[94mlambda\u001b[0m x: metric(x).item()                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.second_metric = second_metric                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update_cur_metric()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/Automatic-Circuit-Discovery/acdc/\u001b[0m\u001b[1;33macdc_utils.py\u001b[0m:\u001b[94m52\u001b[0m in \u001b[92mkl_divergence\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   │   \u001b[0mbase_model_logprobs = base_model_logprobs[:, -\u001b[94m1\u001b[0m, :]                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   \u001b[0mlogprobs = F.log_softmax(logits, dim=-\u001b[94m1\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 52 \u001b[2m│   \u001b[0mkl_div = F.kl_div(logprobs, base_model_logprobs, log_target=\u001b[94mTrue\u001b[0m, reduction=\u001b[33m\"\u001b[0m\u001b[33mnone\u001b[0m\u001b[33m\"\u001b[0m).   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m mask_repeat_candidates \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m kl_div.shape == mask_repeat_candidates.shape, (kl_div.shape, mask_repeat_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2928\u001b[0m in \u001b[92mkl_div\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2925 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2926 \u001b[0m\u001b[2m│   │   │   \u001b[0mreduction_enum = _Reduction.get_enum(reduction)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2927 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2928 \u001b[2m│   \u001b[0mreduced = torch.kl_div(\u001b[96minput\u001b[0m, target, reduction_enum, log_target=log_target)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2929 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2930 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m reduction == \u001b[33m\"\u001b[0m\u001b[33mbatchmean\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m \u001b[96minput\u001b[0m.dim() != \u001b[94m0\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2931 \u001b[0m\u001b[2m│   │   \u001b[0mreduced = reduced / \u001b[96minput\u001b[0m.size()[\u001b[94m0\u001b[0m]                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m2.81\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.65\u001b[0m GiB total capacity; \u001b[1;36m18.90\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m1.53\u001b[0m GiB free; \u001b[1;36m18.93\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory\n",
       "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make notes for potential wandb run\n",
    "try:\n",
    "    with open(__file__, \"r\") as f:\n",
    "        notes = f.read()\n",
    "except:\n",
    "    notes = \"No notes generated, expected when running in an .ipynb file\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "\n",
    "# Save some mem\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Setup wandb if needed\n",
    "if WANDB_RUN_NAME is None or IPython.get_ipython() is not None:\n",
    "    WANDB_RUN_NAME = f\"{ct()}{'_randomindices' if INDICES_MODE=='random' else ''}_{THRESHOLD}{'_zero' if ZERO_ABLATION else ''}\"\n",
    "else:\n",
    "    assert WANDB_RUN_NAME is not None, \"I want named runs, always\"\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "exp = TLACDCExperiment(\n",
    "    model=tl_model,\n",
    "    threshold=THRESHOLD,\n",
    "    using_wandb=USING_WANDB,\n",
    "    wandb_entity_name=WANDB_ENTITY_NAME,\n",
    "    wandb_project_name=WANDB_PROJECT_NAME,\n",
    "    wandb_run_name=WANDB_RUN_NAME,\n",
    "    wandb_group_name=WANDB_GROUP_NAME,\n",
    "    wandb_notes=notes,\n",
    "    wandb_dir=args.wandb_dir,\n",
    "    wandb_mode=args.wandb_mode,\n",
    "    wandb_config=args,\n",
    "    zero_ablation=ZERO_ABLATION,\n",
    "    ds=toks_int_values,\n",
    "    ref_ds=toks_int_values_other,\n",
    "    metric=validation_metric,\n",
    "    second_metric=second_metric,\n",
    "    verbose=True,\n",
    "    indices_mode=INDICES_MODE,\n",
    "    names_mode=NAMES_MODE,\n",
    "    second_cache_cpu=SECOND_CACHE_CPU,\n",
    "    hook_verbose=False,\n",
    "    first_cache_cpu=FIRST_CACHE_CPU,\n",
    "    add_sender_hooks=True,\n",
    "    use_pos_embed=use_pos_embed,\n",
    "    add_receiver_hooks=False,\n",
    "    remove_redundant=False,\n",
    "    show_full_index=use_pos_embed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d98bf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h2>Run steps of ACDC: iterate over a NODE in the model's computational graph</h2>\n",
    "<p>WARNING! This will take a few minutes to run, but there should be rolling nice pictures too : )</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2f126",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(args.max_num_epochs):\n",
    "    exp.step(testing=False)\n",
    "\n",
    "    show(\n",
    "        exp.corr,\n",
    "        f\"ims/img_new_{i+1}.png\",\n",
    "        show_full_index=use_pos_embed,\n",
    "    )\n",
    "\n",
    "    if IN_COLAB or ipython is not None:\n",
    "        # so long as we're not running this as a script, show the image!\n",
    "        display(Image(f\"ims/img_new_{i+1}.png\"))\n",
    "\n",
    "    print(i, \"-\" * 50)\n",
    "    print(exp.count_no_edges())\n",
    "\n",
    "    if i == 0:\n",
    "        exp.save_edges(\"edges.pkl\")\n",
    "\n",
    "    if exp.current_node is None or SINGLE_STEP:\n",
    "        break\n",
    "\n",
    "exp.save_edges(\"another_final_edges.pkl\")\n",
    "\n",
    "if USING_WANDB:\n",
    "    edges_fname = f\"edges.pth\"\n",
    "    exp.save_edges(edges_fname)\n",
    "    artifact = wandb.Artifact(edges_fname, type=\"dataset\")\n",
    "    artifact.add_file(edges_fname)\n",
    "    wandb.log_artifact(artifact)\n",
    "    os.remove(edges_fname)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e9903",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h2>Save the final subgraph of the model</h2>\n",
    "<p>There are more than `exp.count_no_edges()` here because we include some \"placeholder\" edges needed to make ACDC work that don't actually matter</p>\n",
    "<p>Also note that the final image has more than 12 edges, because the edges from a0.0_q and a0.0_k are not connected to the input</p>\n",
    "<p>We recover minimal induction machinery! `embed -> a0.0_v -> a1.6k`</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a39668",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.save_subgraph(\n",
    "    return_it=True,\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.412468,
   "end_time": "2023-06-06T20:01:08.488124",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/_converted/main_demo.ipynb",
   "output_path": "notebooks/colabs/ACDC_Main_Demo.ipynb",
   "parameters": {},
   "start_time": "2023-06-06T20:00:06.075656",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}