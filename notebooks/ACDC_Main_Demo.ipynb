{"cells":[{"cell_type":"markdown","source":[" This notebook / script shows several use cases of ACDC\n","\n"," (The code relies on our modification of the TransformerLens codebase,\n"," mainly giving all HookPoints access to a global cache)\n"," Janky code to do different setup when run in a Colab notebook vs VSCode (cribbed from e.g https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb)"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","\n","    from IPython import get_ipython\n","    ipython = get_ipython()\n","\n","    ipython.run_line_magic(\"pip\", \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git@arthur-try-merge-tl\")\n","    ipython \n","\n","    %pip install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git@arthur-try-merge-tl # TODO update to remove the specific branch install when we finish merging!\n","    %pip install torchtyping\n","    %pip install git+https://github.com/deepmind/tracr.git@e75ecdaec12bf2d831a60e54d4270e8fa31fb537#egg=tracr\n","    %pip install cmapy\n","\n","    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n","    # # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","\n","except Exception as e:\n","    print(f\"The error looks like {e}\")\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\")\n","\n","    import plotly\n","    plotly.io.renderers.default = \"colab\" # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n","    # disable this option when developing rather than generating notebook outputs\n","\n","    from IPython import get_ipython\n","    ipython = get_ipython()\n","    if ipython is not None:\n","        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n","        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore"],"outputs":[{"output_type":"stream","name":"stdout","text":["The error looks like No module named 'google.colab'\n","Running as a Jupyter notebook - intended for development only! (This is also used for automatically generating notebook outputs)\n"]}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["import wandb\n","import IPython\n","import torch\n","import gc\n","from tqdm import tqdm\n","import networkx as nx\n","import os\n","import torch\n","import huggingface_hub\n","import graphviz\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from tqdm import tqdm\n","import yaml\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.io as pio\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","\n","from transformer_lens.hook_points import HookedRootModule, HookPoint\n","from transformer_lens.graphics import show\n","from transformer_lens.HookedTransformer import (\n","    HookedTransformer,\n",")\n","from transformer_lens.tracr.utils import get_all_tracr_things, get_tracr_model_input_and_tl_model\n","from transformer_lens.docstring.utils import get_all_docstring_things\n","from transformer_lens.acdc_utils import (\n","    make_nd_dict,\n","    reset_network,\n","    shuffle_tensor,\n","    cleanup,\n","    ct,\n","    TorchIndex,\n","    Edge,\n","    EdgeType,\n",")  # these introduce several important classes !!!\n","\n","from transformer_lens.TLACDCCorrespondence import TLACDCCorrespondence\n","from transformer_lens.TLACDCInterpNode import TLACDCInterpNode\n","from transformer_lens.TLACDCExperiment import TLACDCExperiment\n","\n","from transformer_lens.acdc_utils import (\n","    kl_divergence,\n",")\n","from transformer_lens.ioi.utils import (\n","    get_all_ioi_things,\n","    get_gpt2_small,\n",")\n","from transformer_lens.induction.utils import (\n","    get_all_induction_things,\n","    get_validation_data,\n","    get_good_induction_candidates,\n","    get_mask_repeat_candidates,\n",")\n","from transformer_lens.greaterthan.utils import get_all_greaterthan_things\n","from transformer_lens.graphics import (\n","    build_colorscheme,\n","    show,\n",")\n","import argparse\n","torch.autograd.set_grad_enabled(False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7f6e0278b0d0>"]},"metadata":{},"execution_count":2}],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["parser = argparse.ArgumentParser(description=\"Used to launch ACDC runs. Only task and threshold are required\")\n","parser.add_argument('--task', type=str, required=True, choices=['ioi', 'docstring', 'induction', 'tracr-reverse', 'tracr-proportion', 'greaterthan'], help='Choose a task from the available options: ioi, docstring, induction, tracr (WIPs)')\n","parser.add_argument('--threshold', type=float, required=True, help='Value for THRESHOLD')\n","parser.add_argument('--first-cache-cpu', type=bool, required=False, default=True, help='Value for FIRST_CACHE_CPU')\n","parser.add_argument('--second-cache-cpu', type=bool, required=False, default=True, help='Value for SECOND_CACHE_CPU')\n","parser.add_argument('--zero-ablation', action='store_true', help='Use zero ablation')\n","parser.add_argument('--using-wandb', action='store_true', help='Use wandb')\n","parser.add_argument('--wandb-entity-name', type=str, required=False, default=\"remix_school-of-rock\", help='Value for WANDB_ENTITY_NAME')\n","parser.add_argument('--wandb-group-name', type=str, required=False, default=\"default\", help='Value for WANDB_GROUP_NAME')\n","parser.add_argument('--wandb-project-name', type=str, required=False, default=\"acdc\", help='Value for WANDB_PROJECT_NAME')\n","parser.add_argument('--wandb-run-name', type=str, required=False, default=None, help='Value for WANDB_RUN_NAME')\n","parser.add_argument(\"--wandb-dir\", type=str, default=\"/tmp/wandb\")\n","parser.add_argument(\"--wandb-mode\", type=str, default=\"online\")\n","parser.add_argument('--indices-mode', type=str, default=\"normal\")\n","parser.add_argument('--names-mode', type=str, default=\"normal\")\n","parser.add_argument('--device', type=str, default=\"cuda\")\n","parser.add_argument('--reset-network', type=int, default=0, help=\"Whether to reset the network we're operating on before running interp on it\")\n","parser.add_argument('--metric', type=str, default=\"kl_div\", help=\"Which metric to use for the experiment\")\n","parser.add_argument('--torch-num-threads', type=int, default=0, help=\"How many threads to use for torch (0=all)\")\n","parser.add_argument('--seed', type=int, default=1234)\n","parser.add_argument(\"--max-num-epochs\",type=int, default=100_000)\n","parser.add_argument('--single-step', action='store_true', help='Use single step, mostly for testing')\n","\n","# for now, force the args to be the same as the ones in the notebook, later make this a CLI tool\n","if IPython.get_ipython() is not None: # heheh get around this failing in notebooks\n","    # args = parser.parse_args(\"--threshold 1.733333 --zero-ablation\".split())\n","    # args = parser.parse_args(\"--threshold 0.001 --using-wandb\".split())\n","    args = parser.parse_args(\"--task tracr-proportion --zero-ablation --using-wandb --threshold 0.005 --wandb-project-name acdc --indices-mode reverse --first-cache-cpu False --second-cache-cpu False\".split())\n","else:\n","    args = parser.parse_args()\n","\n","\n","if args.torch_num_threads > 0:\n","    torch.set_num_threads(args.torch_num_threads)\n","torch.manual_seed(args.seed)\n","\n","TASK = args.task\n","FIRST_CACHE_CPU = args.first_cache_cpu\n","SECOND_CACHE_CPU = args.second_cache_cpu\n","THRESHOLD = args.threshold # only used if >= 0.0\n","ZERO_ABLATION = True if args.zero_ablation else False\n","USING_WANDB = True if args.using_wandb else False\n","WANDB_ENTITY_NAME = args.wandb_entity_name\n","WANDB_PROJECT_NAME = args.wandb_project_name\n","WANDB_RUN_NAME = args.wandb_run_name\n","WANDB_GROUP_NAME = args.wandb_group_name\n","INDICES_MODE = args.indices_mode\n","NAMES_MODE = args.names_mode\n","DEVICE = args.device\n","RESET_NETWORK = args.reset_network\n","SINGLE_STEP = True if args.single_step else False"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["# Setup\n","\n","second_metric = None # some tasks only have one metric\n","use_pos_embed = TASK.startswith(\"tracr\")\n","\n","if TASK == \"ioi\":\n","    num_examples = 100\n","    things = get_all_ioi_things(num_examples=num_examples, device=DEVICE, metric_name=args.metric)\n","elif TASK == \"tracr-reverse\":\n","    num_examples = 6\n","    things = get_all_tracr_things(task=\"reverse\", metric_name=args.metric, num_examples=num_examples, device=DEVICE)\n","elif TASK == \"tracr-proportion\":\n","    num_examples = 50\n","    things = get_all_tracr_things(task=\"proportion\", metric_name=args.metric, num_examples=num_examples, device=DEVICE)\n","elif TASK == \"induction\":\n","    num_examples = 50\n","    seq_len = 300\n","    # TODO initialize the `tl_model` with the right model\n","    things = get_all_induction_things(num_examples=num_examples, seq_len=seq_len, device=DEVICE, metric=args.metric)\n","\n","elif TASK == \"docstring\":\n","    num_examples = 50\n","    seq_len = 41\n","    things = get_all_docstring_things(num_examples=num_examples, seq_len=seq_len, device=DEVICE,\n","                                                metric_name=args.metric, correct_incorrect_wandb=True)\n","elif TASK == \"greaterthan\":\n","    num_examples = 100\n","    things = get_all_greaterthan_things(num_examples=num_examples, metric_name=args.metric, device=DEVICE)\n","else:\n","    raise ValueError(f\"Unknown task {TASK}\")\n","\n","\n","validation_metric = things.validation_metric\n","\n","toks_int_values = things.validation_data\n","toks_int_values_other = things.validation_patch_data\n","\n","tl_model = things.tl_model\n","\n","if RESET_NETWORK:\n","    reset_network(TASK, DEVICE, tl_model)"],"outputs":[{"output_type":"stream","name":"stderr","text":["No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["if IN_COLAB:\n","    notes = \"No notes; using colab\"\n","else:\n","    with open(__file__, \"r\") as f:\n","        notes = f.read()\n","\n","tl_model.reset_hooks()\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","if WANDB_RUN_NAME is None or IPython.get_ipython() is not None:\n","    WANDB_RUN_NAME = f\"{ct()}{'_randomindices' if INDICES_MODE=='random' else ''}_{THRESHOLD}{'_zero' if ZERO_ABLATION else ''}\"\n","else:\n","    assert WANDB_RUN_NAME is not None, \"I want named runs, always\"\n","\n","tl_model.reset_hooks()\n","exp = TLACDCExperiment(\n","    model=tl_model,\n","    threshold=THRESHOLD,\n","    using_wandb=USING_WANDB,\n","    wandb_entity_name=WANDB_ENTITY_NAME,\n","    wandb_project_name=WANDB_PROJECT_NAME,\n","    wandb_run_name=WANDB_RUN_NAME,\n","    wandb_group_name=WANDB_GROUP_NAME,\n","    wandb_notes=notes,\n","    wandb_dir=args.wandb_dir,\n","    wandb_mode=args.wandb_mode,\n","    wandb_config=args,\n","    zero_ablation=ZERO_ABLATION,\n","    ds=toks_int_values,\n","    ref_ds=toks_int_values_other,\n","    metric=validation_metric,\n","    second_metric=second_metric,\n","    verbose=True,\n","    indices_mode=INDICES_MODE,\n","    names_mode=NAMES_MODE,\n","    second_cache_cpu=SECOND_CACHE_CPU,\n","    hook_verbose=False,\n","    first_cache_cpu=FIRST_CACHE_CPU,\n","    add_sender_hooks=True,\n","    use_pos_embed=use_pos_embed,\n","    add_receiver_hooks=False,\n","    remove_redundant=False,\n","    show_full_index=use_pos_embed,\n",")\n","\n","# exp.load_from_wandb_run(\"remix_school-of-rock\", \"acdc\", \"c4bixuq5\")\n","# # ^that line of code can scrape from a WANDB run\n","# print(exp.count_no_edges()) # should be 6 for that run"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["for i in range(args.max_num_epochs):\n","\n","    exp.step(testing=False) # TODO why aren't we while looping to completion ???\n","\n","    show(\n","        exp.corr,\n","        f\"ims/img_new_{i+1}.png\",\n","        show_full_index=use_pos_embed,\n","    )\n","    print(i, \"-\" * 50)\n","    print(exp.count_no_edges())\n","\n","    if i==0:\n","        exp.save_edges(\"edges.pkl\")\n","\n","    if exp.current_node is None or SINGLE_STEP:\n","        break\n","\n","exp.save_edges(\"another_final_edges.pkl\")\n","\n","\n","# TODO evaluate on test data set\n","\n","if USING_WANDB:\n","    edges_fname = f\"edges.pth\"\n","    exp.save_edges(edges_fname)\n","    artifact = wandb.Artifact(edges_fname, type='dataset')\n","    artifact.add_file(edges_fname)\n","    wandb.log_artifact(artifact)\n","    os.remove(edges_fname)\n","    wandb.finish()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["exp.save_subgraph(\n","    return_it=True,\n",")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["px.imshow(torch.randn(4, 5)) # used to check notebook rendering works fine"],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}